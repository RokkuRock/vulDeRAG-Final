# âœ… å®Œæ•´å›è£œç‰ˆç¨‹å¼ç¢¼ï¼ˆfile_with_vul_snippet-pure_chain-of-thought-pipeline.pyï¼‰
# âœ… å·²ä¿®æ­£ END è¼¸å…¥è¡Œç‚ºã€ä¿ç•™å®Œæ•´ snippet æ¨¡å¼åŠŸèƒ½ã€ä¸Šä¸‹æ–‡æ•´åˆèˆ‡äº’å‹•åˆ†ææµç¨‹

import json
import re
from pathlib import Path
from langchain_core.documents import Document
from typing import List
import argparse
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

try:
    from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline
    from langchain_chroma import Chroma
except ImportError:
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_community.llms import HuggingFacePipeline

from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline
from peft import PeftModel
import torch
from new_cwe_crawler import CWECollector

class IntegratedRAGPipeline:
    def __init__(self, model_path="./DeepSeek-R1-Distill-Llama-8B", db_dir="./chroma_db"):
        self.model_path = model_path
        self.db_dir = db_dir
        self.vectordb = None
        self.llm = None
        self.cwe_collector = CWECollector(delay=1)

    def summarize_similar_cwe_types(self, examples):
        summary = "è«‹åƒè€ƒä»¥ä¸‹ CWE å¼±é»é¡å‹é€²è¡Œä¿®å¾©åˆ¤æ–·ï¼š\n"
        for i, ex in enumerate(examples, 1):
            cwe = ex.metadata.get("cwe_id", "CWE-???")
            title = ex.metadata.get("example_title", "Unknown Example")
            summary += f"{i}. {cwe} - {title}\n"
        return summary.strip()

    def build_focused_repair_prompt(self, full_code, vulnerable_snippet, similar_examples):
        cwe_summary = self.summarize_similar_cwe_types(similar_examples)
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç†Ÿæ‚‰æ‰€æœ‰ç¨‹å¼èªè¨€å®‰å…¨æ¼æ´ä¿®å¾©çš„å°ˆå®¶ã€‚
è«‹æ ¹æ“šä¸‹æ–¹è³‡è¨Šé€²è¡Œå®Œæ•´ä¿®å¾©å»ºè­°ï¼š

=== CWE å¼±é»æ‘˜è¦ ===
{cwe_summary}

=== å®Œæ•´ç¨‹å¼ç¢¼ä¸Šä¸‹æ–‡ ===
```
{full_code[:1800]}{'...(truncated)' if len(full_code) > 1800 else ''}
```

=== èšç„¦ç‰‡æ®µ (æ‡·ç–‘æœ‰æ¼æ´) ===
```
{vulnerable_snippet.strip()}
```

=== å‘é‡è³‡æ–™åº«ä¸­çš„ CWE ç›¸ä¼¼ç¯„ä¾‹ ===
"""
        for i, example in enumerate(similar_examples, 1):
            cwe_id = example.metadata.get('cwe_id', 'Unknown')
            title = example.metadata.get('example_title', 'Unknown')
            code = example.metadata.get('original_snippet', '').strip()
            prompt += f"""
[ç¯„ä¾‹ {i}] {cwe_id} - {title}
```
{code[:500]}...
```
"""
        prompt += f"""
è«‹æ ¹æ“šä¸Šæ–¹è³‡è¨Šå›ç­”ä»¥ä¸‹å•é¡Œï¼š

Q1: ç¨‹å¼ç¢¼å¯èƒ½å­˜åœ¨ä»€éº¼é¡å‹çš„æ¼æ´ï¼Ÿè«‹èªªæ˜ä¾æ“šã€‚
Q2: æ¼æ´å…·é«”å‡ºç¾åœ¨ç¨‹å¼ç¢¼çš„å“ªå€‹ä½ç½®ï¼Ÿ
Q3: é€™å€‹æ¼æ´å¯èƒ½é€ æˆä»€éº¼æ¨£çš„å®‰å…¨é¢¨éšªï¼Ÿ
Q4: å»ºè­°çš„ä¿®å¾©ç­–ç•¥æ˜¯ä»€éº¼ï¼Ÿ
Q5: è«‹æä¾›ä¿®å¾©å¾Œçš„å®Œæ•´ç¨‹å¼ç¢¼ã€‚
```
[è«‹åœ¨æ­¤è¼¸å‡ºå®Œæ•´å¯ç·¨è­¯çš„ C ç¨‹å¼ç¢¼ï¼Œéœ€åŒ…å«ä¿®æ­£ç‰‡æ®µèˆ‡å¿…è¦é‚è¼¯]
```
Q6: ä¿®å¾©çš„é—œéµè®Šæ›´æœ‰å“ªäº›ï¼Ÿ
"""
        return prompt

    def get_vulnerable_snippet_input(self):
        print("\nè«‹è¼¸å…¥éœ€è¦èšç„¦åˆ†æçš„ç¨‹å¼ç¢¼ç‰‡æ®µï¼Œè¼¸å…¥ END çµæŸï¼š")
        snippet_lines = []
        while True:
            try:
                line = input()
                if line.strip() == 'END':
                    break
                snippet_lines.append(line)
            except EOFError:
                break
        print("\nâœ… Vulnerable snippet input received, model inferencing...")
        return '\n'.join(snippet_lines)

    def read_code_file(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()

    def find_similar_vulnerabilities(self, code, k=3):
        return self.vectordb.as_retriever(search_kwargs={"k": k}).invoke(code)

    def initialize(self, force_rebuild_db=False, force_recollect_cwe=False):
        embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        self.vectordb = Chroma(persist_directory=self.db_dir, embedding_function=embedding_model)

        bnb_config = BitsAndBytesConfig(load_in_8bit=True)

        base_model = AutoModelForCausalLM.from_pretrained(
            "DeepSeek-R1-Distill-Llama-8B",
            quantization_config=bnb_config,
            device_map="auto",
            torch_dtype=torch.float16
        )

        model = PeftModel.from_pretrained(base_model, self.model_path)
        tokenizer = AutoTokenizer.from_pretrained(self.model_path, use_fast=True)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=2048, temperature=0.1, top_p=0.9)
        self.llm = HuggingFacePipeline(pipeline=pipe)
        print("âœ… System initialization completed!")
        return True

    def run(self, args):
        print("ğŸ” ç¨‹å¼é–‹å§‹åŸ·è¡Œ...")
        print(f"ğŸ“‹ è§£æçµæœ: input={args.input}, snippet={args.snippet}, model_path={args.model_path}")
        print("ğŸ” æ•´åˆå¼ RAG æ¼æ´ä¿®å¾©ç³»çµ± (ç°¡åŒ–ç‰ˆ)")
        print("="*60)

        if args.input:
            if not Path(args.input).exists():
                print(f"âŒ éŒ¯èª¤: æ–‡ä»¶ä¸å­˜åœ¨ - {args.input}")
                return
            if not self.initialize(force_rebuild_db=args.rebuild, force_recollect_cwe=args.recollect):
                print("âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
                return
            full_code = self.read_code_file(args.input)
            if args.snippet:
                snippet = self.get_vulnerable_snippet_input()
                if snippet:
                    similar = self.find_similar_vulnerabilities(snippet)
                    prompt = self.build_focused_repair_prompt(full_code, snippet, similar)
                    result = self.llm.invoke(prompt)
                    print("\nğŸ”§ åˆ†æçµæœ:\n", result)
            else:
                similar = self.find_similar_vulnerabilities(full_code)
                prompt = self.build_focused_repair_prompt(full_code, full_code, similar)
                result = self.llm.invoke(prompt)
                print("\nğŸ”§ åˆ†æçµæœ:\n", result)

# âœ… ä¸»ç¨‹å¼å…¥å£

def main():
    parser = argparse.ArgumentParser(description="RAG æ¼æ´ä¿®å¾©ç³»çµ±")
    parser.add_argument('-i', '--input', type=str, help='æŒ‡å®šè¦åˆ†æçš„ç¨‹å¼ç¢¼æ–‡ä»¶')
    parser.add_argument('-s', '--snippet', action='store_true', help='å•Ÿç”¨ vulnerable snippet æ¨¡å¼')
    parser.add_argument('--model-path', type=str, default="./DeepSeek-R1-Distill-Llama-8B")
    parser.add_argument('--db-dir', type=str, default="./chroma_db")
    parser.add_argument('--rebuild', action='store_true')
    parser.add_argument('--recollect', action='store_true')
    args = parser.parse_args()
    pipeline = IntegratedRAGPipeline(model_path=args.model_path, db_dir=args.db_dir)
    pipeline.run(args)

if __name__ == '__main__':
    main()
