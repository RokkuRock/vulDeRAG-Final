import json
import re
from pathlib import Path
from langchain_core.documents import Document
from typing import List
import argparse 

# Handle deprecation warnings
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

try:
    from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline
    from langchain_chroma import Chroma
except ImportError:
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_community.llms import HuggingFacePipeline

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

# Import CWE collector (crawler version)
from new_cwe_crawler import CWECollector, get_common_cwe_ids

class IntegratedRAGPipeline:
    """Integrated RAG Vulnerability Repair System - Using DeepSeek-R1-Distill-Llama-8B (Simplified)"""
    
    def __init__(self, model_path="./DeepSeek-R1-Distill-Llama-8B", db_dir="./chroma_db"):
        self.model_path = model_path
        self.db_dir = db_dir
        self.vectordb = None
        self.llm = None
        self.cwe_collector = CWECollector(delay=1)
        self.cwe_examples_file = "cwe_examples.json"
    
    # æ–°å¢æ–¹æ³•: è®€å–ç¨‹å¼ç¢¼æ–‡ä»¶
    def read_code_file(self, file_path):
        """è®€å–ç¨‹å¼ç¢¼æ–‡ä»¶ä¸¦è¿”å›å…§å®¹"""
        try:
            file_path = Path(file_path)
            if not file_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if not content.strip():
                print(f"âš ï¸ æ–‡ä»¶å…§å®¹ç‚ºç©º: {file_path}")
                return None
            
            print(f"âœ… æˆåŠŸè®€å–æ–‡ä»¶: {file_path} ({len(content)} å­—ç¬¦)")
            return content
            
        except Exception as e:
            print(f"âŒ è®€å–æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None

    # æ–°å¢æ–¹æ³•: è™•ç†å–®å€‹æ–‡ä»¶çš„æ¼æ´ä¿®å¾©
    def repair_file_vulnerability(self, file_path):
        """è™•ç†å–®å€‹æ–‡ä»¶çš„æ¼æ´ä¿®å¾©"""
        if not self.vectordb or not self.llm:
            print("[ERROR] ç³»çµ±æœªå®Œå…¨åˆå§‹åŒ–")
            return False
        
        # è®€å–æ–‡ä»¶å…§å®¹
        user_code = self.read_code_file(file_path)
        if user_code is None:
            return False
        
        try:
            print("\n" + "="*60)
            print(f"ğŸ” é–‹å§‹åˆ†ææ–‡ä»¶: {file_path}")
            print("="*60)
            
            result, similar_examples = self.repair_vulnerability(user_code)
            
            print("\n" + "="*50)
            if similar_examples:
                print("ğŸ“‹ åƒè€ƒçš„ç›¸ä¼¼æ¼æ´ç¯„ä¾‹:")
                for i, example in enumerate(similar_examples, 1):
                    cwe_id = example.metadata.get('cwe_id', 'Unknown')
                    title = example.metadata.get('example_title', 'Unknown')
                    print(f"  {i}. {cwe_id} - {title}")
            
            print("\n" + "="*50)
            print("ğŸ”§ æ¼æ´åˆ†æèˆ‡ä¿®å¾©çµæœ:")
            print("="*50)
            print(result)
            print("="*50)
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«ç¨‹å¼ç¢¼å€å¡Š
            code_blocks = re.findall(r'```[\s\S]*?```', result)
            if code_blocks:
                print(f"\nâœ… ç”Ÿæˆäº† {len(code_blocks)} å€‹ç¨‹å¼ç¢¼å€å¡Š")
            else:
                print("\nğŸ“ åˆ†æå®Œæˆ (å¯èƒ½åŒ…å«å»ºè­°ä½†ç„¡ç¨‹å¼ç¢¼å€å¡Š)")
            
            return True
                
        except Exception as e:
            print(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            print(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            return False

    # === STEP 1: CWE Data Collection and Processing ===
    def collect_or_load_cwe_data(self, cwe_ids=None, use_cache=True, force_recollect=False):
        """Collect or load CWE vulnerability example data"""
        cache_path = Path(self.cwe_examples_file)
        
        # Check if forced recollection is needed
        if force_recollect and cache_path.exists():
            print(f"[INFO] Force recollection, deleting old cache file: {self.cwe_examples_file}")
            cache_path.unlink()
        
        # Check cache file
        if use_cache and cache_path.exists():
            print(f"[INFO] Loading CWE data from cache: {self.cwe_examples_file}")
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    # Check data format
                    if 'cwe_examples' in cached_data:
                        cwe_examples = cached_data['cwe_examples']
                    elif isinstance(cached_data, dict) and all(isinstance(k, (str, int)) for k in cached_data.keys()):
                        # Direct cwe_examples format
                        cwe_examples = cached_data
                    else:
                        print("[WARN] Cache file format incorrect, will recollect data")
                        cwe_examples = None
                    
                    if cwe_examples:
                        total_examples = sum(len(examples) for examples in cwe_examples.values())
                        print(f"[INFO] Successfully loaded {len(cwe_examples)} CWE types, total {total_examples} examples")
                        return cwe_examples
            except Exception as e:
                print(f"[WARN] Failed to load cache file: {e}")
        
        # Collect new data
        if cwe_ids is None:
            cwe_ids = get_common_cwe_ids()[:1000]  # Limit quantity to avoid taking too long
        
        print(f"[INFO] Starting to collect example data for {len(cwe_ids)} CWEs via crawler...")
        print("=" * 50)
        
        cwe_examples = self.cwe_collector.collect_multiple_cwes(cwe_ids)
        
        if not cwe_examples:
            print("[ERROR] Unable to collect CWE data")
            return {}
        
        # Save as JSON format
        try:
            output_data = {
                "collection_info": {
                    "total_cwes": len(cwe_examples),
                    "total_examples": sum(len(examples) for examples in cwe_examples.values()),
                    "cwe_ids": list(cwe_examples.keys())
                },
                "cwe_examples": cwe_examples
            }
            
            with open(self.cwe_examples_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            
            total_examples = sum(len(examples) for examples in cwe_examples.values())
            print(f"[INFO] CWE data saved to: {self.cwe_examples_file}")
            print(f"[INFO] Successfully collected {len(cwe_examples)} CWE types, total {total_examples} examples")
            
        except Exception as e:
            print(f"[WARN] Error occurred while saving CWE data: {e}")
        
        return cwe_examples
    
    def cwe_to_documents(self, cwe_examples):
        """Convert CWE data to Document format - å€åˆ†ä¿®å¾©å‰å’Œä¿®å¾©å¾Œçš„ç¨‹å¼ç¢¼"""
        documents = []

        def filter_metadata(meta_dict):
            """åªä¿ç•™åŸºæœ¬å‹åˆ¥çš„ metadataï¼ˆstr, int, float, bool, Noneï¼‰"""
            return {k: v for k, v in meta_dict.items() if isinstance(v, (str, int, float, bool, type(None)))}

        for cwe_id, examples in cwe_examples.items():
            # Handle different formats of cwe_id (could be string or integer)
            cwe_id_str = str(cwe_id)

            for i, example in enumerate(examples):
                is_fixed = example.get('is_fixed', False)
                code_type = "fixed" if is_fixed else "vulnerable"
                background_color = example.get('background_color', 'none')

                metadata = {
                    "cwe_id": f"CWE-{cwe_id_str}",
                    "vulnerability_type": f"CWE-{cwe_id_str}",
                    "example_title": example.get('title', f'Example {i+1}'),
                    "source": example.get('source', 'crawler'),
                    "file": f"cwe_{cwe_id_str}_example_{i+1}",
                    "bug_block_id": f"{cwe_id_str}_{i+1}",
                    "original_snippet": example.get('code', ''),
                    "code_type": code_type,
                    "is_fixed": is_fixed,
                    "background_color": background_color,
                    "doc_id": f"CWE-{cwe_id_str}_{code_type}_{i+1}"
                }

                # å¯é¸ï¼šå°‡ computed_styles çš„èƒŒæ™¯è‰²ä»¥æ–‡å­—ä¿ç•™ï¼ˆä¸ä¿ç•™ dictï¼‰
                if 'computed_styles' in example:
                    cs = example['computed_styles']
                    if isinstance(cs, dict):
                        if 'background-color' in cs:
                            metadata['computed_style_bg'] = cs['background-color']

                # Content format optimized for vector search
                content_prefix = "Fixed Code" if is_fixed else "Vulnerable Code"
                content = f"""Vulnerability Type: CWE-{cwe_id_str}
    Code Type: {content_prefix}
    Example Title: {example.get('title', f'Example {i+1}')}
    Code:
    {example.get('code', '')}"""

                documents.append(Document(
                    page_content=content,
                    metadata=filter_metadata(metadata)  # éæ¿¾éæ³• metadata
                ))

        # çµ±è¨ˆè³‡è¨Š
        total_docs = len(documents)
        vulnerable_docs = len([d for d in documents if not d.metadata.get('is_fixed', False)])
        fixed_docs = len([d for d in documents if d.metadata.get('is_fixed', False)])

        print(f"[INFO] Conversion completed: {total_docs} documents")
        print(f"[INFO] - Vulnerable code documents: {vulnerable_docs}")
        print(f"[INFO] - Fixed code documents: {fixed_docs}")

        return documents

    
    # === STEP 2: Vector Database Construction ===
    def build_or_load_vectordb(self, force_rebuild=False, force_recollect_cwe=False):
        """Build or load vector database"""
        db_path = Path(self.db_dir)
        
        if not force_rebuild and db_path.exists() and not force_recollect_cwe:
            print("[INFO] Loading existing vector database...")
            try:
                embedding_model = HuggingFaceEmbeddings(
                    model_name="sentence-transformers/all-MiniLM-L6-v2"
                )
                self.vectordb = Chroma(
                    persist_directory=self.db_dir,
                    embedding_function=embedding_model
                )
                print("[SUCCESS] Vector database loaded successfully!")
                return True
            except Exception as e:
                print(f"[WARN] Failed to load existing database: {e}")
                print("[INFO] Will rebuild database...")
        
        # Build new vector database
        print("[INFO] Building new vector database...")
        
        # Collect CWE data
        cwe_examples = self.collect_or_load_cwe_data(force_recollect=force_recollect_cwe)
        if not cwe_examples:
            print("[ERROR] Unable to collect or load CWE data")
            return False
        
        # Convert to documents
        documents = self.cwe_to_documents(cwe_examples)
        if not documents:
            print("[ERROR] Unable to create documents")
            return False
        
        # Create vector database
        try:
            # If database directory exists, delete it first
            if db_path.exists():
                import shutil
                shutil.rmtree(db_path)
                print("[INFO] Deleted old vector database")
            
            embedding_model = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2"
            )
            
            self.vectordb = Chroma.from_documents(
                documents=documents,
                embedding=embedding_model,
                persist_directory=self.db_dir
            )
            
            # Persist database
            try:
                self.vectordb.persist()
            except AttributeError:
                # New version of Chroma auto-persists
                pass
                
            print(f"[SUCCESS] Vector database construction completed! Contains {len(documents)} documents")
            return True
            
        except Exception as e:
            print(f"[ERROR] Vector database construction failed: {e}")
            return False
    
    # === STEP 3: Load Llama 3.1 Model ===
    def load_llm(self):
        """Load local DeepSeek-R1-Distill-Llama-8B model"""
        try:
            print("[INFO] Loading local DeepSeek-R1-Distill-Llama-8B model...")
            
            tokenizer = AutoTokenizer.from_pretrained(self.model_path, use_fast=True)
            
            # Set pad_token if not present
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
            
            model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                device_map="auto",
                torch_dtype=torch.float16,
                trust_remote_code=True
            )
            
            pipe = pipeline(
                "text-generation",
                model=model,
                tokenizer=tokenizer,
                max_new_tokens=2048,
                temperature=0.1,
                top_p=0.9,
                repetition_penalty=1.15,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id
            )
            
            self.llm = HuggingFacePipeline(pipeline=pipe)
            print("[SUCCESS] DeepSeek-R1-Distill-Llama-8B model loaded successfully!")
            return True
            
        except Exception as e:
            print(f"[ERROR] Model loading failed: {e}")
            return False
    
    # === STEP 4: Similarity Search ===
    def find_similar_vulnerabilities(self, user_code, k=3):
        """Search for similar vulnerability examples"""
        if not self.vectordb:
            print("[ERROR] Vector database not initialized")
            return []
        
        try:
            retriever = self.vectordb.as_retriever(search_kwargs={"k": k})
            similar_docs = retriever.invoke(user_code)
            return similar_docs
        except AttributeError:
            # Fallback to old API
            retriever = self.vectordb.as_retriever(search_kwargs={"k": k})
            similar_docs = retriever.get_relevant_documents(user_code)
            return similar_docs
    
    # === STEP 5: Build Repair Prompt ===
    def build_repair_prompt(self, user_code, similar_examples):
        """å»ºæ§‹Chain-of-Thought Q&Aæ ¼å¼çš„ä¿®å¾©æç¤ºè©"""
        
        prompt = f"""ä½œç‚ºå°ˆæ¥­çš„ç¨‹å¼ç¢¼å®‰å…¨å°ˆå®¶ï¼Œè«‹é€éä»¥ä¸‹å•ç­”æ­¥é©Ÿä¾†åˆ†æå’Œä¿®å¾©ç¨‹å¼ç¢¼æ¼æ´ã€‚

    === åƒè€ƒç›¸ä¼¼æ¼æ´ç¯„ä¾‹ ===
    """
        
        for i, example in enumerate(similar_examples, 1):
            cwe_id = example.metadata.get('cwe_id', 'Unknown')
            example_title = example.metadata.get('example_title', 'Unknown')
            original_snippet = example.metadata.get('original_snippet', '')
            
            prompt += f"""
    ã€åƒè€ƒç¯„ä¾‹ {i}ã€‘{cwe_id} - {example_title}
    æ¼æ´ç¨‹å¼ç¢¼:
    ```
    {original_snippet[:500]}...
    ```
    """
        
        prompt += f"""

    === å¾…ä¿®å¾©çš„ç¨‹å¼ç¢¼ ===
    ```
    {user_code}
    ```

    è«‹æŒ‰ç…§ä»¥ä¸‹Chain-of-Thoughtå•ç­”æ ¼å¼é€²è¡Œåˆ†æï¼š

    Q1: é€™æ®µç¨‹å¼ç¢¼å¯èƒ½å­˜åœ¨ä»€éº¼é¡å‹çš„å®‰å…¨æ¼æ´ï¼Ÿ
    A1: [è«‹æ ¹æ“šç¨‹å¼ç¢¼ç‰¹å¾µå’Œåƒè€ƒç¯„ä¾‹ï¼Œè­˜åˆ¥å¯èƒ½çš„æ¼æ´é¡å‹ï¼Œä¾‹å¦‚ï¼šç·©è¡å€æº¢å‡ºã€ä½¿ç”¨å¾Œé‡‹æ”¾ã€SQLæ³¨å…¥ç­‰ï¼Œä¸¦èªªæ˜åˆ¤æ–·ä¾æ“š]

    Q2: æ¼æ´å…·é«”ä½æ–¼ç¨‹å¼ç¢¼çš„å“ªå€‹ä½ç½®ï¼Ÿ
    A2: [è«‹æŒ‡å‡ºå…·é«”çš„è¡Œæ•¸ã€å‡½æ•¸åç¨±æˆ–ç¨‹å¼ç¢¼å€å¡Šï¼Œèªªæ˜ç‚ºä»€éº¼é€™äº›ä½ç½®å­˜åœ¨å®‰å…¨é¢¨éšª]

    Q3: é€™å€‹æ¼æ´å¯èƒ½é€ æˆä»€éº¼æ¨£çš„å®‰å…¨å¨è„…ï¼Ÿ
    A3: [è«‹æè¿°æ”»æ“Šè€…å¯èƒ½å¦‚ä½•åˆ©ç”¨æ­¤æ¼æ´ï¼Œä»¥åŠå¯èƒ½é€ æˆçš„æå®³ï¼Œå¦‚è¨˜æ†¶é«”ç ´å£ã€è³‡æ–™æ´©æ¼ã€æ¬Šé™æå‡ç­‰]

    Q4: æ‡‰è©²æ¡ç”¨ä»€éº¼ä¿®å¾©ç­–ç•¥ä¾†è§£æ±ºé€™å€‹æ¼æ´ï¼Ÿ
    A4: [è«‹æ ¹æ“šæ¼æ´é¡å‹æå‡ºå…·é«”çš„ä¿®å¾©æ–¹æ³•ï¼Œå¦‚é‚Šç•Œæª¢æŸ¥ã€è¼¸å…¥é©—è­‰ã€è¨˜æ†¶é«”ç®¡ç†æ”¹å–„ç­‰]

    Q5: ä¿®å¾©å¾Œçš„å®Œæ•´ç¨‹å¼ç¢¼æ‡‰è©²æ˜¯ä»€éº¼æ¨£å­ï¼Ÿ
    A5: **é‡è¦ï¼šå¿…é ˆæä¾›å®Œæ•´çš„ã€å¯ç›´æ¥ç·¨è­¯åŸ·è¡Œçš„ä¿®å¾©å¾Œç¨‹å¼ç¢¼ï¼Œä¸”ä¸å¯ä»¥å®Œå…¨ç…§æŠ„å‘é‡è³‡æ–™åº«æ‰¾åˆ°çš„ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼Œå¿…é ˆæ†‘è‡ªå·±å‰µæ„èˆ‡å¼•ç”¨å‘é‡è³‡æ–™åº«æª¢ç´¢åˆ°çš„ç¯„ä¾‹ä¸­CWEçš„è§€å¿µèˆ‡å¼±é»æ¦‚å¿µï¼Œé€²è¡Œä¿®æ”¹çµ¦å‡ºå…¨æ–°çš„ç¨‹å¼ç¢¼æ–¹æ¡ˆï¼Œæ–¹æ¡ˆåªèƒ½æœ‰ä¸€å€‹Fixed codeè·Ÿä¸€å€‹CWEç·¨è™Ÿ**

    ```
    [åœ¨æ­¤è™•æä¾›å®Œæ•´çš„ä¿®å¾©å¾Œç¨‹å¼ç¢¼ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„headerã€è®Šæ•¸å®£å‘Šã€éŒ¯èª¤è™•ç†ç­‰]
    ```

    Q6: ä¿®å¾©éç¨‹ä¸­åšäº†å“ªäº›é—œéµæ”¹å‹•ï¼Ÿ
    A6: [è«‹è©³ç´°åˆ—å‡ºä¸»è¦çš„ç¨‹å¼ç¢¼è®Šæ›´é»ï¼Œèªªæ˜æ¯å€‹æ”¹å‹•å¦‚ä½•è§£æ±ºåŸæœ‰çš„å®‰å…¨å•é¡Œ]

    Q7: å¦‚ä½•ç¢ºä¿ä¿®å¾©å¾Œä¸æœƒå¼•å…¥æ–°çš„å®‰å…¨å•é¡Œï¼Ÿ
    A7: [è«‹èªªæ˜ä¿®å¾©ç­–ç•¥å¦‚ä½•å¾¹åº•æ¶ˆé™¤æ¼æ´ï¼Œä»¥åŠæ¡å–äº†å“ªäº›é¡å¤–çš„å®‰å…¨æªæ–½]

    Q8: æœ‰ä»€éº¼ç›¸é—œçš„å®‰å…¨ç·¨ç¨‹å»ºè­°å¯ä»¥é é˜²é¡ä¼¼æ¼æ´ï¼Ÿ
    A8: [è«‹æä¾›ç›¸é—œçš„æœ€ä½³å¯¦è¸å»ºè­°å’Œé é˜²é¡ä¼¼æ¼æ´çš„ç·¨ç¨‹ç¿’æ…£]

    **æ³¨æ„äº‹é …ï¼š**
    1. æ¯å€‹å•é¡Œéƒ½å¿…é ˆå®Œæ•´å›ç­”
    2. Q5çš„ä¿®å¾©å¾Œç¨‹å¼ç¢¼å¿…é ˆå®Œæ•´ä¸”å¯åŸ·è¡Œ
    3. ç¢ºä¿ä¿®å¾©ä¸æœƒå¼•å…¥æ–°çš„å®‰å…¨å•é¡Œ
    4. ä¿æŒåŸæœ‰ç¨‹å¼é‚è¼¯çš„æ­£ç¢ºæ€§
    5. æ¯å€‹Qèˆ‡Açš„å•é¡Œçš„è¼¸å‡ºä¸å¾—è¶…é200å€‹tokens

    è«‹é–‹å§‹é€æ­¥å›ç­”æ¯å€‹å•é¡Œï¼š"""
        
        return prompt

    # === STEP 6: Output Processing ===
    def clean_model_output(self, raw_output, original_prompt):
        """Clean model output"""
        if original_prompt in raw_output:
            cleaned = raw_output.split(original_prompt)[-1].strip()
        else:
            cleaned = raw_output.strip()
        
        # Remove common conversation starters
        unwanted_starts = [
            "I'll analyze", "Let me analyze", "I need to analyze",
            "Based on the provided", "First,", "I'll help you", "As a professional",
            "I will analyze for you", "Let me help you analyze"
        ]
        
        for start in unwanted_starts:
            if cleaned.startswith(start):
                lines = cleaned.split('\n')
                for i, line in enumerate(lines):
                    if line.strip().startswith('#') or line.strip().startswith('##') or 'Vulnerability' in line:
                        cleaned = '\n'.join(lines[i:])
                        break
                break
        
        return cleaned
    
    # === STEP 7: Simplified Repair Process ===
    def repair_vulnerability(self, user_code):
        """Execute vulnerability repair - simplified without retries"""
        if not self.vectordb or not self.llm:
            print("[ERROR] System not fully initialized")
            return None, []
        
        print("ğŸ” Searching for similar vulnerability examples...")
        similar_examples = self.find_similar_vulnerabilities(user_code)
        
        if not similar_examples:
            print("[WARN] No similar vulnerability examples found")
            similar_examples = []
        
        print(f"ğŸ“ Found {len(similar_examples)} similar examples, building repair prompt...")
        
        try:
            print("ğŸ”§ Executing repair analysis...")
            
            # Build prompt
            repair_prompt = self.build_repair_prompt(user_code, similar_examples)
            
            # Get result from model
            raw_result = self.llm.invoke(repair_prompt)
            cleaned_result = self.clean_model_output(raw_result, repair_prompt)
            
            # Always return result, even if empty or incomplete
            if not cleaned_result.strip():
                print("âš ï¸ Model output is empty, providing fallback analysis...")
                cleaned_result = self._generate_fallback_analysis(user_code, similar_examples)
            
            print("âœ… Repair analysis completed")
            return cleaned_result, similar_examples
            
        except Exception as e:
            print(f"âŒ Error during processing: {str(e)}")
            # Provide fallback analysis even on error
            fallback_result = self._generate_fallback_analysis(user_code, similar_examples)
            return fallback_result, similar_examples
    
    def _generate_fallback_analysis(self, user_code, similar_examples):
        """Generate basic fallback analysis when model fails"""
        analysis = "## Vulnerability Analysis\n"
        analysis += "**Status**: Model analysis failed, providing basic assessment\n\n"
        
        # Basic vulnerability detection
        if 'gets(' in user_code:
            analysis += "**Detected Issue**: Buffer overflow vulnerability (CWE-120)\n"
            analysis += "**Problem**: Use of unsafe `gets()` function\n\n"
            analysis += "## Suggested Fix:\n"
            analysis += "```c\n"
            analysis += user_code.replace('gets(', 'fgets(').replace('gets(name)', 'fgets(name, sizeof(name), stdin)')
            analysis += "\n```\n\n"
            analysis += "## Key Changes:\n"
            analysis += "- Replace `gets()` with `fgets()` to prevent buffer overflow\n"
            analysis += "- Specify buffer size limit in `fgets()`\n"
        elif 'strcpy(' in user_code:
            analysis += "**Detected Issue**: Potential buffer overflow (CWE-120)\n"
            analysis += "**Problem**: Use of unsafe `strcpy()` function\n\n"
            analysis += "## Suggested Fix:\n"
            analysis += "```c\n"
            analysis += user_code.replace('strcpy(', 'strncpy(')
            analysis += "\n```\n\n"
            analysis += "## Key Changes:\n"
            analysis += "- Replace `strcpy()` with `strncpy()` for bounded copying\n"
        elif 'sprintf(' in user_code:
            analysis += "**Detected Issue**: Potential buffer overflow (CWE-120)\n"
            analysis += "**Problem**: Use of unsafe `sprintf()` function\n\n"
            analysis += "## Suggested Fix:\n"
            analysis += "```c\n"
            analysis += user_code.replace('sprintf(', 'snprintf(')
            analysis += "\n```\n\n"
            analysis += "## Key Changes:\n"
            analysis += "- Replace `sprintf()` with `snprintf()` for bounded formatting\n"
        else:
            analysis += "**Status**: No obvious vulnerabilities detected in basic scan\n"
            analysis += "**Recommendation**: Manual security review recommended\n\n"
            analysis += "## Original Code:\n"
            analysis += "```c\n"
            analysis += user_code
            analysis += "\n```\n"
        
        if similar_examples:
            analysis += f"\n## Referenced Examples:\n"
            for i, example in enumerate(similar_examples[:3], 1):
                cwe_id = example.metadata.get('cwe_id', 'Unknown')
                title = example.metadata.get('example_title', 'Unknown')
                analysis += f"- {cwe_id}: {title}\n"
        
        return analysis
    
    # === STEP 8: System Initialization ===
    def initialize(self, force_rebuild_db=False, force_recollect_cwe=False):
        """Initialize the entire system"""
        print("ğŸš€ Initializing RAG Vulnerability Repair System...")
        
        # Build vector database
        if not self.build_or_load_vectordb(force_rebuild_db, force_recollect_cwe):
            print("[ERROR] Vector database initialization failed")
            return False
        
        # Load model
        if not self.load_llm():
            print("[ERROR] Model loading failed")
            return False
        
        print("âœ… System initialization completed!")
        return True
    
    # === STEP 9: Interactive Interface ===
    def run_interactive(self):
        """Run interactive repair interface"""
        print("\n" + "="*60)
        print("ğŸ”’ RAG Vulnerability Repair System - Interactive Mode")
        print("="*60)
        print("Enter code snippets for vulnerability analysis and repair")
        print("Enter 'exit' to end program, 'help' to view instructions")
        print("="*60)
        
        while True:
            print("\nPlease enter your code snippet (multi-line input, enter 'END' to finish):")
            
            user_code_lines = []
            while True:
                try:
                    line = input()
                    if line.strip() == 'END':
                        break
                    elif line.strip().lower() == 'exit':
                        print("ğŸ‘‹ Thank you for using!")
                        return
                    elif line.strip().lower() == 'help':
                        self.show_help()
                        break
                    user_code_lines.append(line)
                except KeyboardInterrupt:
                    print("\nProgram interrupted")
                    return
            
            if line.strip().lower() == 'help':
                continue
            
            user_code = '\n'.join(user_code_lines)
            
            if not user_code.strip():
                print("âš ï¸ Code input is empty, please re-enter")
                continue
            
            try:
                print("\n" + "="*50)
                print("ğŸ” Starting code vulnerability analysis...")
                
                result, similar_examples = self.repair_vulnerability(user_code)
                
                print("\n" + "="*50)
                if similar_examples:
                    print("ğŸ“‹ Referenced similar vulnerability examples:")
                    for i, example in enumerate(similar_examples, 1):
                        cwe_id = example.metadata.get('cwe_id', 'Unknown')
                        title = example.metadata.get('example_title', 'Unknown')
                        print(f"  {i}. {cwe_id} - {title}")
                
                print("\n" + "="*50)
                print("ğŸ”§ Vulnerability Analysis and Repair Results:")
                print("="*50)
                print(result)
                print("="*50)
                
                # Check if it contains code blocks
                code_blocks = re.findall(r'```[\s\S]*?```', result)
                if code_blocks:
                    print(f"\nâœ… Generated {len(code_blocks)} code blocks")
                else:
                    print("\nğŸ“ Analysis completed (may contain recommendations without code blocks)")
                    
            except Exception as e:
                print(f"âŒ Error occurred during processing: {str(e)}")
                import traceback
                print(f"Detailed error: {traceback.format_exc()}")
            
            print("\nContinue analyzing other code? (y/n/exit)")
            choice = input().strip().lower()
            if choice in ['n', 'no', 'exit']:
                break
        
        print("ğŸ‘‹ Thank you for using the RAG Vulnerability Repair System!")
    
    def show_help(self):
        """Display help information"""
        print("\n" + "="*50)
        print("ğŸ“– User Guide - RAG Vulnerability Repair System")
        print("="*50)
        print("ğŸ¯ System Features:")
        print("  âœ“ Always provides analysis output")
        print("  âœ“ Fallback analysis when model fails")
        print("  âœ“ Basic vulnerability detection")
        print("\nğŸ“ Usage:")
        print("1. Enter code snippet to be analyzed")
        print("2. System searches for similar vulnerabilities and generates repair solution")
        print("3. Provides repair recommendations or complete code")
        print("\nğŸ”§ Supported Vulnerability Types:")
        print("   - Buffer Overflow (CWE-120, CWE-121, CWE-122)")
        print("   - Use After Free (CWE-416)")
        print("   - SQL Injection (CWE-89)")
        print("   - Cross-Site Scripting (CWE-79)")
        print("   - Memory Leak (CWE-401)")
        print("   - And more common vulnerability types...")
        print("\nğŸ’¡ Tips:")
        print("   - Enter 'exit' to end program")
        print("   - System will always provide some form of analysis")
        print("   - Recommend providing complete functions or program segments")
        print("="*50)
    
    # === View collected CWE data statistics ===
    def show_cwe_statistics(self):
        """Display statistics of collected CWE data"""
        cache_path = Path(self.cwe_examples_file)
        if not cache_path.exists():
            print(f"[INFO] CWE data file does not exist: {self.cwe_examples_file}")
            return
        
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if 'collection_info' in data:
                info = data['collection_info']
                print(f"\n=== CWE Data Statistics ===")
                print(f"Total CWE Types: {info.get('total_cwes', 0)}")
                print(f"Total Examples: {info.get('total_examples', 0)}")
                print(f"CWE ID List: {info.get('cwe_ids', [])}")
            
            cwe_examples = data.get('cwe_examples', data)
            print(f"\n=== Number of Examples per CWE Type ===")
            for cwe_id, examples in cwe_examples.items():
                print(f"CWE-{cwe_id}: {len(examples)} examples")
            
        except Exception as e:
            print(f"[ERROR] Failed to read CWE data statistics: {e}")

# ===== ä¿®æ”¹ä½ç½®3: å®Œå…¨æ›¿æ› main() å‡½æ•¸ =====
def main():
    """ä¸»ç¨‹å¼ - æ”¯æ´å‘½ä»¤è¡Œåƒæ•¸"""
    try:
        print("ğŸ”’ ç¨‹å¼é–‹å§‹åŸ·è¡Œ...")  # æ·»åŠ èª¿è©¦ä¿¡æ¯
        
        # è¨­ç½®å‘½ä»¤è¡Œåƒæ•¸è§£æ
        parser = argparse.ArgumentParser(description='RAG æ¼æ´ä¿®å¾©ç³»çµ±')
        parser.add_argument('-i', '--input', type=str, help='æŒ‡å®šè¦åˆ†æçš„ç¨‹å¼ç¢¼æ–‡ä»¶è·¯å¾‘')
        parser.add_argument('--model-path', type=str, default="./DeepSeek-R1-Distill-Llama-8B", 
                           help='æŒ‡å®šæ¨¡å‹è·¯å¾‘ (é è¨­: ./DeepSeek-R1-Distill-Llama-8B)')
        parser.add_argument('--db-dir', type=str, default="./chroma_db", 
                           help='æŒ‡å®šå‘é‡è³‡æ–™åº«ç›®éŒ„ (é è¨­: ./chroma_db)')
        parser.add_argument('--rebuild', action='store_true', 
                           help='å¼·åˆ¶é‡å»ºå‘é‡è³‡æ–™åº«')
        parser.add_argument('--recollect', action='store_true', 
                           help='å¼·åˆ¶é‡æ–°æ”¶é›† CWE è³‡æ–™')
        parser.add_argument('--stats', action='store_true', 
                           help='é¡¯ç¤º CWE è³‡æ–™çµ±è¨ˆ')
        
        print("ğŸ” è§£æå‘½ä»¤è¡Œåƒæ•¸...")  # æ·»åŠ èª¿è©¦ä¿¡æ¯
        args = parser.parse_args()
        print(f"ğŸ“‹ è§£æçµæœ: input={args.input}, model_path={args.model_path}")  # æ·»åŠ èª¿è©¦ä¿¡æ¯
        
        print("ğŸ”’ æ•´åˆå¼ RAG æ¼æ´ä¿®å¾©ç³»çµ± (ç°¡åŒ–ç‰ˆ)")
        print("="*60)
        
        # å¦‚æœåªæ˜¯è¦æŸ¥çœ‹çµ±è¨ˆè³‡è¨Š
        if args.stats:
            print("ğŸ“Š é€²å…¥çµ±è¨ˆæ¨¡å¼...")
            pipeline = IntegratedRAGPipeline(model_path=args.model_path, db_dir=args.db_dir)
            pipeline.show_cwe_statistics()
            return
        
        # å¦‚æœæŒ‡å®šäº†è¼¸å…¥æ–‡ä»¶ï¼Œé€²è¡Œæ–‡ä»¶åˆ†ææ¨¡å¼
        if args.input:
            print(f"ğŸ“ é€²å…¥æ–‡ä»¶åˆ†ææ¨¡å¼: {args.input}")
            
            # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(args.input).exists():
                print(f"âŒ éŒ¯èª¤: æ–‡ä»¶ä¸å­˜åœ¨ - {args.input}")
                print(f"ğŸ“‚ ç•¶å‰å·¥ä½œç›®éŒ„: {Path.cwd()}")
                print(f"ğŸ“‹ ç›®éŒ„å…§å®¹:")
                try:
                    for item in Path.cwd().iterdir():
                        if item.is_file() and item.suffix in ['.c', '.cpp', '.py', '.java']:
                            print(f"   - {item.name}")
                except Exception as e:
                    print(f"   ç„¡æ³•åˆ—å‡ºç›®éŒ„å…§å®¹: {e}")
                return
            
            print("ğŸš€ åˆå§‹åŒ–ç³»çµ±...")
            # æª¢æŸ¥æ¨¡å‹è·¯å¾‘
            if not Path(args.model_path).exists():
                print(f"[WARN] æ¨¡å‹è·¯å¾‘ä¸å­˜åœ¨: {args.model_path}")
                print("è«‹ç¢ºä¿ DeepSeek-R1-Distill-Llama-8B æ¨¡å‹å·²ä¸‹è¼‰åˆ°æŒ‡å®šè·¯å¾‘")
                model_path = input("è«‹è¼¸å…¥æ­£ç¢ºçš„æ¨¡å‹è·¯å¾‘ (æˆ–æŒ‰ Enter è·³é): ").strip()
                if not model_path:
                    print("âš ï¸ è·³éæ¨¡å‹æª¢æŸ¥ï¼Œç¹¼çºŒåŸ·è¡Œ...")
                else:
                    args.model_path = model_path
            
            # åˆå§‹åŒ–ç³»çµ±
            pipeline = IntegratedRAGPipeline(model_path=args.model_path, db_dir=args.db_dir)
            
            print("âš™ï¸ æ­£åœ¨åˆå§‹åŒ–ç³»çµ±çµ„ä»¶...")
            if not pipeline.initialize(force_rebuild_db=args.rebuild, force_recollect_cwe=args.recollect):
                print("[ERROR] ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
                return
            
            print("ğŸ”§ é–‹å§‹è™•ç†æ–‡ä»¶...")
            # è™•ç†æŒ‡å®šçš„æ–‡ä»¶
            success = pipeline.repair_file_vulnerability(args.input)
            if success:
                print(f"\nâœ… æ–‡ä»¶ {args.input} åˆ†æå®Œæˆï¼")
            else:
                print(f"\nâŒ æ–‡ä»¶ {args.input} åˆ†æå¤±æ•—ï¼")
            return
        
        # æ²’æœ‰æŒ‡å®šæ–‡ä»¶æ™‚ï¼Œé€²å…¥äº’å‹•æ¨¡å¼
        print("\nâš ï¸ æœªæŒ‡å®šè¼¸å…¥æ–‡ä»¶ï¼Œé€²å…¥äº’å‹•æ¨¡å¼")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨ -i <æ–‡ä»¶å> åƒæ•¸å¯ç›´æ¥åˆ†ææŒ‡å®šæ–‡ä»¶")
        
        # æª¢æŸ¥æ¨¡å‹è·¯å¾‘
        if not Path(args.model_path).exists():
            print(f"[WARN] æ¨¡å‹è·¯å¾‘ä¸å­˜åœ¨: {args.model_path}")
            print("è«‹ç¢ºä¿ DeepSeek-R1-Distill-Llama-8B æ¨¡å‹å·²ä¸‹è¼‰åˆ°æŒ‡å®šè·¯å¾‘")
            model_path = input("è«‹è¼¸å…¥æ­£ç¢ºçš„æ¨¡å‹è·¯å¾‘: ").strip()
            if not model_path:
                print("âŒ æœªæä¾›æœ‰æ•ˆçš„æ¨¡å‹è·¯å¾‘ï¼Œç¨‹å¼çµæŸ")
                return
            args.model_path = model_path
        
        # åˆå§‹åŒ–ç³»çµ±
        pipeline = IntegratedRAGPipeline(model_path=args.model_path, db_dir=args.db_dir)
        
        print("\né¸æ“‡åˆå§‹åŒ–æ¨¡å¼:")
        print("1. ä½¿ç”¨ç¾æœ‰è³‡æ–™ (å¦‚æœå¯ç”¨)")
        print("2. å®Œå…¨é‡å»º")
        print("3. æŸ¥çœ‹ CWE è³‡æ–™çµ±è¨ˆ")
        
        choice = input("è«‹é¸æ“‡ (1/2/3): ").strip()
        
        if choice == "3":
            pipeline.show_cwe_statistics()
            return
        elif choice == "2":
            force_rebuild_db = True
            force_recollect_cwe = True
        else:  # choice == "1" or default
            force_rebuild_db = False
            force_recollect_cwe = False
        
        if not pipeline.initialize(force_rebuild_db=force_rebuild_db, force_recollect_cwe=force_recollect_cwe):
            print("[ERROR] ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
            return
        
        # å•Ÿå‹•äº’å‹•ä»‹é¢
        pipeline.run_interactive()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ¶ä¸­æ–·ç¨‹å¼åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤:")
        print(f"éŒ¯èª¤é¡å‹: {type(e).__name__}")
        print(f"éŒ¯èª¤è¨Šæ¯: {str(e)}")
        import traceback
        print(f"è©³ç´°è¿½è¹¤:")
        traceback.print_exc()
    finally:
        print("ğŸ”š ç¨‹å¼çµæŸ")

if __name__ == "__main__":
    main()
